name: Manual SPSC Benchmarks

on:
  workflow_dispatch:
    inputs:
      pr_number:
        description: 'Pull request number to benchmark'
        required: true
        type: number
      runner_labels:
        description: 'Comma-separated additional labels for the self-hosted benchmark runner (e.g. "linux")'
        required: false
        default: ''
        type: string

permissions:
  contents: read
  pull-requests: write

env:
  CARGO_TERM_COLOR: always
  CARGO_TARGET_DIR: ${{ github.workspace }}/.bench-target

jobs:
  prepare-runner-labels:
    runs-on: ubuntu-latest
    outputs:
      runner_labels_list: ${{ steps.build-labels.outputs.runner_labels_list }}
    steps:
      - name: Build runner label list
        id: build-labels
        shell: bash
        run: |
          labels="${{ inputs.runner_labels }}"
          labels="${labels// /}"                 # strip spaces
          labels="${labels//,/\",\"}"            # turn comma list into quoted csv
          echo "runner_labels_list=[\"self-hosted\",\"bench\"${labels:+,\"$labels\"}]" >> "$GITHUB_OUTPUT"

  benchmark:
    name: Bench PR #${{ inputs.pr_number }}
    needs: prepare-runner-labels
    runs-on: ${{ fromJson(needs.prepare-runner-labels.outputs.runner_labels_list) }}
    outputs:
      pr_number: ${{ steps.parse-pr.outputs.pr_number }}

    steps:
      - name: Harden Runner
        uses: step-security/harden-runner@95d9a5deda9de15063e7595e9719c11c38c90ae2 # v2.13.2
        with:
          egress-policy: audit

      - name: Parse PR number as integer
        id: parse-pr
        run: |
          # Parse PR number as integer (handle float inputs like "10.0")
          pr_int=$(printf "%.0f" "${{ inputs.pr_number }}")
          echo "pr_number=${pr_int}" >> "$GITHUB_OUTPUT"

      - name: Comment benchmark start on PR
        id: progress-comment
        uses: actions/github-script@ed597411d8f924073f98dfc5c65a23a2325f34cd # v8.0.0
        with:
          script: |
            // Use the parsed PR number integer
            const prNumber = ${{ steps.parse-pr.outputs.pr_number }};
            const body = `Benchmark run started on runner label(s) \`${{ inputs.runner_labels }}\`...`;
            const { data: comment } = await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: prNumber,
              body,
            });
            core.setOutput('comment_id', comment.id);

      - name: Checkout PR head
        uses: actions/checkout@1af3b93b6815bc44a9784bd300feb67ff0d1eeb3 # v6.0.0
        with:
          ref: refs/pull/${{ steps.parse-pr.outputs.pr_number }}/head
          fetch-depth: 0

      - name: Checkout main for baseline
        uses: actions/checkout@1af3b93b6815bc44a9784bd300feb67ff0d1eeb3 # v6.0.0
        with:
          ref: main
          path: main-baseline
          fetch-depth: 0

      - name: Record main commit
        id: main_sha
        run: echo "sha=$(git -C main-baseline rev-parse HEAD)" >> "$GITHUB_OUTPUT"

      - name: Install Rust toolchain
        uses: dtolnay/rust-toolchain@0b1efabc08b657293548b77fb76cc02d26091c7e # stable channel installer
        with:
          toolchain: stable

      - name: Cache Rust build artifacts
        uses: Swatinem/rust-cache@f13886b937689c021905a6b90929199931d60db1 # v2.8.1
        with:
          shared-key: bench-${{ runner.name }}
          workspaces: |
            .
            main-baseline
          cache-on-failure: true

      - name: Restore cached main baseline measurements
        id: baseline-cache
        uses: actions/cache@0057852bfaa89a56745cba8c7296529d2fc39830 # v4.3.0
        with:
          path: ${{ env.CARGO_TARGET_DIR }}/criterion
          key: criterion-main-${{ runner.name }}-${{ steps.main_sha.outputs.sha }}

      - name: Run baseline on main (only if missing)
        if: steps.baseline-cache.outputs.cache-hit != 'true'
        working-directory: main-baseline
        run: cargo bench --bench spsc-throughput -- --measurement-time 20 --sample-size 50 --save-baseline main

      - name: Save baseline cache (before PR run)
        if: steps.baseline-cache.outputs.cache-hit != 'true'
        uses: actions/cache/save@0057852bfaa89a56745cba8c7296529d2fc39830 # v4.3.0
        with:
          path: ${{ env.CARGO_TARGET_DIR }}/criterion
          key: criterion-main-${{ runner.name }}-${{ steps.main_sha.outputs.sha }}

      - name: Run benchmarks for PR against main baseline
        id: bench-pr
        run: |
          cargo bench --bench spsc-throughput -- --measurement-time 20 --sample-size 50 --baseline main 2>&1 | tee bench_output.txt

      - name: Upload criterion reports
        uses: actions/upload-artifact@330a01c490aca151604b8cf639adc76d48f6c5d4 # v5.0.0
        with:
          name: pr-${{ steps.parse-pr.outputs.pr_number }}-bench-${{ github.run_id }}
          path: ${{ env.CARGO_TARGET_DIR }}/criterion

      - name: Parse benchmark results
        id: parse-results
        run: |
          # Parse Criterion output to extract benchmark results
          # Look for lines with "change:" to identify performance deltas
          
          {
            echo "## Benchmark Results"
            echo ""
            echo "| Benchmark | Runtime Change | Status |"
            echo "|-----------|----------------|--------|"
          } > results.md
          
          # Parse the benchmark output
          # Criterion outputs lines like:
          # "spsc//cap32_payload32_batch1"
          # "                        time:   [201.34 ms 206.26 ms 210.69 ms]"
          # "                 change:"
          # "                        time:   [-8.2272% -5.7068% -3.1975%] (p = 0.00 < 0.05)"
          # "                        Performance has improved."
          
          awk '
            BEGIN { 
              # Default benchmark group prefix to strip from display names
              benchmark_group = "spsc//"
            }
            # Match benchmark name lines (lines that start with non-whitespace and contain /)
            /^[^ \t]/ && /\// {
              # If we have a previous benchmark with change data, output it
              if (current_bench != "" && current_change != "") {
                display_name = current_bench
                if (index(display_name, benchmark_group) == 1) {
                  display_name = substr(display_name, length(benchmark_group) + 1)
                }
                # Only output if we have a status (no random "Changed" emoji)
                if (current_status != "") {
                  print "| `" display_name "` | " current_change " | " current_status " |"
                }
              }
              
              # Start tracking new benchmark
              current_bench = $0
              current_change = ""
              current_status = ""
              current_time = ""
              time_unit = ""
            }
            # Look for current time in "time:" line before change section
            /^ *time: *\[/ && !in_change_section {
              # Extract the middle value from [lower middle upper]
              # Format: [201.34 ms 206.26 ms 210.69 ms]
              # After split: [1]=201.34 [2]=ms [3]=206.26 [4]=ms [5]=210.69 [6]=ms
              match($0, /\[([^]]+)\]/, arr)
              split(arr[1], times, " ")
              # Verify we have enough elements (at least 4 for value and unit)
              if (length(times) >= 4) {
                current_time = times[3]
                time_unit = times[4]
              }
            }
            # Look for "change:" header line
            /^ *change:$/ {
              in_change_section = 1
              next
            }
            # After "change:" header, look for the time line with percentages
            in_change_section == 1 && /^ *time: *\[/ {
              # Extract change percentage range (the middle value from the three values)
              # Format: [-8.2272% -5.7068% -3.1975%]
              # After split: [1]=-8.2272% [2]=-5.7068% [3]=-3.1975%
              match($0, /\[([^]]+)\]/, arr)
              split(arr[1], changes, " ")
              
              # Verify we have at least 2 elements
              if (length(changes) >= 2) {
                change_pct = changes[2]
                
                # Calculate actual time change if we have current time
                # The "time:" line before "change:" shows the current (PR) time
                # The change% = (current - baseline) / baseline * 100
                # So: baseline = current / (1 + change%/100)
                # And: time_delta = current - baseline
                if (current_time != "" && time_unit != "") {
                  # Extract percentage value without % sign
                  pct_val = change_pct
                  gsub(/%/, "", pct_val)
                  
                  # Guard against division by zero (when change is exactly -100%)
                  denominator = 1 + pct_val / 100.0
                  if (denominator != 0) {
                    # Calculate the baseline time and delta
                    baseline_val = current_time / denominator
                    time_delta = current_time - baseline_val
                    
                    # Format the output with proper sign
                    if (time_delta >= 0) {
                      current_change = sprintf("+%.2f %s (%s)", time_delta, time_unit, change_pct)
                    } else {
                      current_change = sprintf("%.2f %s (%s)", time_delta, time_unit, change_pct)
                    }
                  } else {
                    # Edge case: -100% change means time went to zero
                    current_change = sprintf("%.2f %s (%s)", -current_time, time_unit, change_pct)
                  }
                } else {
                  # Fallback to just percentage if we cannot parse time
                  current_change = change_pct
                }
              }
              
              in_change_section = 0
            }
            # Capture status lines that follow change lines
            /Performance has regressed/ {
              current_status = "⚠️ Regressed"
            }
            /Performance has improved/ {
              current_status = "✅ Improved"
            }
            /No change in performance detected/ {
              current_status = "➖ No Change"
            }
            /Change within noise threshold/ {
              current_status = "➖ No Change (within noise)"
            }
            # Handle the last benchmark at end of file
            END {
              if (current_bench != "" && current_change != "") {
                display_name = current_bench
                if (index(display_name, benchmark_group) == 1) {
                  display_name = substr(display_name, length(benchmark_group) + 1)
                }
                if (current_status != "") {
                  print "| `" display_name "` | " current_change " | " current_status " |"
                }
              }
            }
          ' bench_output.txt >> results.md
          
          # If no results were found (only header lines remain), add a note
          # Count lines that look like benchmark results (containing backticks)
          result_count=$(tail -n +4 results.md | grep -c '`' || true)
          if [ "$result_count" -eq 0 ]; then
            echo "| No benchmark comparisons found | - | - |" >> results.md
          fi
          
          {
            echo ""
            echo "_Baseline: main @ \`${{ steps.main_sha.outputs.sha }}\`_"
          } >> results.md
          
          # Output for next step
          cat results.md

      - name: Comment benchmark artifact on PR
        if: success()
        uses: actions/github-script@ed597411d8f924073f98dfc5c65a23a2325f34cd # v8.0.0
        with:
          script: |
            const fs = require('fs');
            // Use the parsed PR number integer
            const prNumber = ${{ steps.parse-pr.outputs.pr_number }};
            const runUrl = `https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}`;
            const artifactName = `pr-${prNumber}-bench-${context.runId}`;
            
            // Read parsed results
            let resultsTable = '';
            try {
              resultsTable = fs.readFileSync('results.md', 'utf8');
            } catch (err) {
              resultsTable = '_No benchmark results could be parsed._';
            }
            
            const body = [
              `Benchmark run completed for PR #${prNumber}.`,
              ``,
              resultsTable,
              ``,
              `---`,
              ``,
              `- Run: ${runUrl}`,
              `- Artifact: ${artifactName} (reports + baseline/compare data)`
            ].join('\n');

            const commentId = "${{ steps.progress-comment.outputs.comment_id }}";
            if (commentId) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: commentId,
                body,
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: prNumber,
                body,
              });
            }

      - name: Comment benchmark failure on PR
        if: failure()
        uses: actions/github-script@ed597411d8f924073f98dfc5c65a23a2325f34cd # v8.0.0
        with:
          script: |
            // Use the parsed PR number integer
            const prNumber = ${{ steps.parse-pr.outputs.pr_number }};
            const runUrl = `https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}`;
            
            const body = [
              `⚠️ Benchmark run failed for PR #${prNumber}.`,
              ``,
              `Please check the [workflow run](${runUrl}) for details.`
            ].join('\n');

            const commentId = "${{ steps.progress-comment.outputs.comment_id }}";
            if (commentId) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: commentId,
                body,
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: prNumber,
                body,
              });
            }
