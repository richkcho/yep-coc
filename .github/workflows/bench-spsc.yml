name: Manual SPSC Benchmarks

on:
  workflow_dispatch:
    inputs:
      pr_number:
        description: 'Pull request number to benchmark'
        required: true
        type: number
      runner_labels:
        description: 'Comma-separated additional labels for the self-hosted benchmark runner (e.g. "linux")'
        required: false
        default: ''
        type: string
      make_comment:
        description: 'Post benchmark results as a comment on the PR'
        required: false
        default: true
        type: boolean

permissions:
  contents: read
  pull-requests: write

env:
  CARGO_TERM_COLOR: always
  CARGO_TARGET_DIR: ${{ github.workspace }}/.bench-target

jobs:
  prepare-runner-labels:
    runs-on: ubuntu-latest
    outputs:
      runner_labels_list: ${{ steps.build-labels.outputs.runner_labels_list }}
    steps:
      - name: Build runner label list
        id: build-labels
        shell: bash
        run: |
          labels="${{ inputs.runner_labels }}"
          labels="${labels// /}"                 # strip spaces
          labels="${labels//,/\",\"}"            # turn comma list into quoted csv
          echo "runner_labels_list=[\"self-hosted\",\"bench\"${labels:+,\"$labels\"}]" >> "$GITHUB_OUTPUT"

  benchmark:
    name: ${{ inputs.pr_number == 0 && 'Bench main' || format('Bench PR {0}', inputs.pr_number) }}
    needs: prepare-runner-labels
    runs-on: ${{ fromJson(needs.prepare-runner-labels.outputs.runner_labels_list) }}
    outputs:
      pr_number: ${{ steps.parse-pr.outputs.pr_number }}

    steps:
      - name: Harden Runner
        uses: step-security/harden-runner@95d9a5deda9de15063e7595e9719c11c38c90ae2 # v2.13.2
        with:
          egress-policy: audit

      - name: Parse PR number as integer
        id: parse-pr
        run: |
          # Parse PR number as integer (handle float inputs like "10.0")
          pr_int=$(printf "%.0f" "${{ inputs.pr_number }}")
          {
            echo "pr_number=${pr_int}"
            if [ "$pr_int" -eq 0 ]; then
              echo "is_main_run=true"
              echo "target_ref=main"
              echo "run_label=main"
            else
              echo "is_main_run=false"
              echo "target_ref=refs/pull/${pr_int}/head"
              echo "run_label=pr-${pr_int}"
            fi
          } >> "$GITHUB_OUTPUT"

      - name: Comment benchmark start on PR
        if: steps.parse-pr.outputs.is_main_run != 'true' && inputs.make_comment == true
        id: progress-comment
        uses: actions/github-script@ed597411d8f924073f98dfc5c65a23a2325f34cd # v8.0.0
        with:
          script: |
            // Use the parsed PR number integer
            const prNumber = ${{ steps.parse-pr.outputs.pr_number }};
            const body = `Benchmark run started on runner label(s) \`${{ inputs.runner_labels }}\`...`;
            const { data: comment } = await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: prNumber,
              body,
            });
            core.setOutput('comment_id', comment.id);

      - name: Checkout target
        uses: actions/checkout@1af3b93b6815bc44a9784bd300feb67ff0d1eeb3 # v6.0.0
        with:
          ref: ${{ steps.parse-pr.outputs.target_ref }}
          fetch-depth: 0

      - name: Checkout main for baseline
        uses: actions/checkout@1af3b93b6815bc44a9784bd300feb67ff0d1eeb3 # v6.0.0
        with:
          ref: main
          path: main-baseline
          fetch-depth: 0

      - name: Record main commit
        id: main_sha
        run: echo "sha=$(git -C main-baseline rev-parse HEAD)" >> "$GITHUB_OUTPUT"

      - name: Install Rust toolchain
        uses: dtolnay/rust-toolchain@0b1efabc08b657293548b77fb76cc02d26091c7e # stable channel installer
        with:
          toolchain: stable

      - name: Cache Rust build artifacts
        uses: Swatinem/rust-cache@f13886b937689c021905a6b90929199931d60db1 # v2.8.1
        with:
          shared-key: bench-${{ runner.name }}
          workspaces: |
            .
            main-baseline
          cache-on-failure: true

      - name: Restore cached main baseline measurements
        id: baseline-cache
        uses: actions/cache@0057852bfaa89a56745cba8c7296529d2fc39830 # v4.3.0
        with:
          path: ${{ env.CARGO_TARGET_DIR }}/criterion
          key: criterion-main-${{ runner.name }}-${{ steps.main_sha.outputs.sha }}
          restore-keys: |
            criterion-main-${{ runner.name }}-

      - name: Run baseline on main (only if missing)
        if: steps.baseline-cache.outputs.cache-hit != 'true'
        working-directory: main-baseline
        run: cargo bench --bench spsc-throughput -- --measurement-time 20 --sample-size 50 --save-baseline main

      - name: Save baseline cache (before PR run)
        if: steps.baseline-cache.outputs.cache-hit != 'true'
        uses: actions/cache/save@0057852bfaa89a56745cba8c7296529d2fc39830 # v4.3.0
        with:
          path: ${{ env.CARGO_TARGET_DIR }}/criterion
          key: criterion-main-${{ runner.name }}-${{ steps.main_sha.outputs.sha }}

      - name: Run benchmarks for PR against main baseline
        id: bench-pr
        run: |
          cargo bench --bench spsc-throughput -- --measurement-time 20 --sample-size 50 --baseline main 2>&1 | tee bench_output.txt

      - name: Upload criterion reports
        uses: actions/upload-artifact@330a01c490aca151604b8cf639adc76d48f6c5d4 # v5.0.0
        with:
          name: pr-${{ steps.parse-pr.outputs.pr_number }}-bench-${{ github.run_id }}
          path: ${{ env.CARGO_TARGET_DIR }}/criterion

      - name: Parse benchmark results
        id: parse-results
        run: |
          # Parse Criterion output to extract benchmark results
          # Look for lines with "change:" to identify performance deltas
          
          {
            echo "## Benchmark Results"
            echo ""
            echo "| Benchmark | Throughput | Status |"
            echo "|-----------|-------------|--------|"
          } > results.md
          
          # Parse the benchmark output
          # Criterion outputs lines like:
          # "spsc//cap32_payload32_batch1"
          # "                        time:   [201.34 ms 206.26 ms 210.69 ms]"
          # "                 change:"
          # "                        time:   [-8.2272% -5.7068% -3.1975%] (p = 0.00 < 0.05)"
          # "                        Performance has improved."
          
          awk '
            BEGIN { 
              # Default benchmark group prefix to strip from display names
              benchmark_group = "spsc//"
            }
            # Match benchmark name lines (lines that start with non-whitespace and contain /)
            /^[^ \t]/ && /\// {
              # If we have a previous benchmark with change data, output it
              if (current_bench != "" && current_change != "") {
                display_name = current_bench
                if (index(display_name, benchmark_group) == 1) {
                  display_name = substr(display_name, length(benchmark_group) + 1)
                }
                # Only output if we have a status (no random "Changed" emoji)
                if (current_status != "") {
                  print "| `" display_name "` | " current_change " | " current_status " |"
                }
              }
              
              # Start tracking new benchmark
              current_bench = $0
              current_change = ""
              current_status = ""
              current_thr = ""
              thr_unit = ""
            }
            # Look for current throughput in "thrpt:" line before change section
            /^ *thrpt: *\[/ && !in_change_section {
              # Extract the middle value from [lower middle upper]
              # Format: [34.030 Melem/s 34.345 Melem/s 34.641 Melem/s]
              # After split: [1]=34.030 [2]=Melem/s [3]=34.345 [4]=Melem/s [5]=34.641 [6]=Melem/s
              match($0, /\[([^]]+)\]/, arr)
              split(arr[1], thrpts, " ")
              if (length(thrpts) >= 4) {
                current_thr = thrpts[3]
                thr_unit = thrpts[4]
              }
            }
            # Look for "change:" header line
            /^ *change:$/ {
              in_change_section = 1
              next
            }
            # After "change:" header, look for the throughput line with percentages
            in_change_section == 1 && /^ *thrpt: *\[/ {
              # Extract change percentage range (the middle value from the three values)
              # Format: [+6.6864% +7.5779% +8.4904%]
              # After split: [1]=+6.6864% [2]=+7.5779% [3]=+8.4904%]
              match($0, /\[([^]]+)\]/, arr)
              split(arr[1], changes, " ")
              
              # Verify we have at least 2 elements
              if (length(changes) >= 2) {
                thrpt_change_str = changes[2]
                
                # Report current throughput with percent change if available
                if (current_thr != "" && thr_unit != "") {
                  current_change = sprintf("%s %s (%s)", current_thr, thr_unit, thrpt_change_str)
                } else {
                  # Fallback to just percentage if we cannot parse throughput
                  current_change = thrpt_change_str
                }
              }
              
              in_change_section = 0
            }
            # Capture status lines that follow change lines
            /Performance has regressed/ {
              current_status = "⚠️ Regressed"
            }
            /Performance has improved/ {
              current_status = "✅ Improved"
            }
            /No change in performance detected/ {
              current_status = "➖ No Change"
            }
            /Change within noise threshold/ {
              current_status = "➖ No Change (within noise)"
            }
            # Handle the last benchmark at end of file
            END {
              if (current_bench != "" && current_change != "") {
                display_name = current_bench
                if (index(display_name, benchmark_group) == 1) {
                  display_name = substr(display_name, length(benchmark_group) + 1)
                }
                if (current_status != "") {
                  print "| `" display_name "` | " current_change " | " current_status " |"
                }
              }
            }
          ' bench_output.txt >> results.md
          
          # If no results were found (only header lines remain), add a note
          # Count lines that look like benchmark results (containing backticks)
          result_count=$(tail -n +4 results.md | grep -c '`' || true)
          if [ "$result_count" -eq 0 ]; then
            echo "| No benchmark comparisons found | - | - |" >> results.md
          fi
          
          {
            echo ""
            echo "_Baseline: main @ \`${{ steps.main_sha.outputs.sha }}\`_"
          } >> results.md
          
          # Output for next step
          cat results.md

      - name: Publish job summary
        if: success()
        run: cat results.md >> "$GITHUB_STEP_SUMMARY"

      - name: Comment benchmark artifact on PR
        if: success() && steps.parse-pr.outputs.is_main_run != 'true' && inputs.make_comment == true
        uses: actions/github-script@ed597411d8f924073f98dfc5c65a23a2325f34cd # v8.0.0
        with:
          script: |
            const fs = require('fs');
            // Use the parsed PR number integer
            const prNumber = ${{ steps.parse-pr.outputs.pr_number }};
            const runUrl = `https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}`;
            const artifactName = `pr-${prNumber}-bench-${context.runId}`;
            
            // Read parsed results
            let resultsTable = '';
            try {
              resultsTable = fs.readFileSync('results.md', 'utf8');
            } catch (err) {
              resultsTable = '_No benchmark results could be parsed._';
            }
            
            const body = [
              `Benchmark run completed for PR #${prNumber}.`,
              ``,
              resultsTable,
              ``,
              `---`,
              ``,
              `- Run: ${runUrl}`,
              `- Artifact: ${artifactName} (reports + baseline/compare data)`
            ].join('\n');

            const commentId = "${{ steps.progress-comment.outputs.comment_id }}";
            if (commentId) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: commentId,
                body,
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: prNumber,
                body,
              });
            }

      - name: Comment benchmark failure on PR
        if: failure() && steps.parse-pr.outputs.is_main_run != 'true' && inputs.make_comment == true
        uses: actions/github-script@ed597411d8f924073f98dfc5c65a23a2325f34cd # v8.0.0
        with:
          script: |
            // Use the parsed PR number integer
            const prNumber = ${{ steps.parse-pr.outputs.pr_number }};
            const runUrl = `https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}`;
            
            const body = [
              `⚠️ Benchmark run failed for PR #${prNumber}.`,
              ``,
              `Please check the [workflow run](${runUrl}) for details.`
            ].join('\n');

            const commentId = "${{ steps.progress-comment.outputs.comment_id }}";
            if (commentId) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: commentId,
                body,
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: prNumber,
                body,
              });
            }
